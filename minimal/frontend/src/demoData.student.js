export const studentModeQuestions = [
  {
    title: 'Transformer Attention Implementation',
    difficulty: 'Intermediate',
    code: [
      'import math',
      'import torch',
      'import torch.nn.functional as F',
      'def attention(query, key, value, mask=None):',
      '    d_k = query.size(-1)',
      '    scores = torch.matmul(query, key.transpose(-2, -1)) / <<math.sqrt(d_k)>>',
      '    ',
      '    if mask is not None:',
      '        scores = scores.masked_fill(<<mask == 0>>, -1e9)',
      '    ',
      '    attention_weights = F.softmax(scores, dim=-1)',
      '    return torch.matmul(attention_weights, value), attention_weights',
    ],
    errors: [
      { id: 'math.sqrt(d_k)', description: 'Should validate d_k > 0; also prefer math.sqrt(float(d_k)) or clamp to avoid domain issues.' },
      { id: 'mask == 0', description: 'Mask logic is inverted for padding; typical masking fills where mask == 1 (or uses an inverted mask).' },
    ],
  },
  {
    title: 'RAG Document Retrieval Pipeline',
    difficulty: 'Beginner',
    code: [
      'import numpy as np',
      'def retrieve_documents(query, embeddings, documents, top_k=5):',
      '    query_embedding = embed_query(query)',
      '    ',
      '    similarities = cosine_similarity(query_embedding, embeddings)',
      '    top_indices = <<similarities.argsort()[-top_k:]>>',
      '    ',
      '    retrieved_docs = [documents[i] for i in top_indices]',
      '    return retrieved_docs, similarities[top_indices]',
    ],
    errors: [
      { id: 'similarities.argsort()[-top_k:]', description: 'argsort() is ascending; this selects the lowest scores. Use argsort()[::-1][:top_k] or argpartition.' },
    ],
  },
  {
    title: 'Modern LLM API Integration',
    difficulty: 'Intermediate',
    code: [
      'import requests',
      'API_URL = "https://api.openai.com/v1/chat/completions"',
      'API_KEY = "sk-..."',
      'def call_openai_api(user_message, max_tokens=1000):',
      '    headers = {"Authorization": f"Bearer {API_KEY}"}',
      '    ',
      '    payload = {',
      '        "model": "gpt-4",',
      '        <<\\"prompt\\": user_message>>,',
      '        "max_tokens": max_tokens,',
      '        "temperature": 0.7',
      '    }',
      '    ',
      '    response = requests.post(API_URL, headers=headers, json=payload)',
      '    return <<response.json()[\\"choices\\"][0][\\"text\\"]>>',
    ],
    errors: [
      { id: '\\"prompt\\": user_message', description: "Use Chat Completions 'messages' array with role/content, not legacy 'prompt'." },
      { id: 'response.json()[\\"choices\\"][0][\\"text\\"]', description: "Chat API returns choices[0].message.content, not .text." },
    ],
  },
  {
    title: 'Fine-tuning Hyperparameter Configuration',
    difficulty: 'Advanced',
    code: [
      'import torch',
      'def setup_fine_tuning(model, train_loader, epochs=10):',
      '    optimizer = torch.optim.AdamW(model.parameters(), <<lr=1e-2>>)',
      '    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, <<step_size=1, gamma=0.1>>)',
      '    ',
      '    for epoch in range(epochs):',
      '        for batch in train_loader:',
      '            optimizer.zero_grad()',
      '            loss = model(batch)',
      '            loss.backward()',
      '            optimizer.step()',
      '        scheduler.step()',
    ],
    errors: [
      { id: 'lr=1e-2', description: 'Too high for fine-tuning transformer models; typical range is 1e-5 to 5e-5.' },
      { id: 'step_size=1, gamma=0.1', description: 'Reducing LR by 10x every epoch is too aggressive; consider a slower schedule (e.g., every 3–5 epochs) or cosine decay.' },
    ],
  },
  {
    title: 'Gradient Accumulation Implementation',
    difficulty: 'Advanced',
    code: [
      'import torch',
      'def train_with_accumulation(model, data_loader, accumulation_steps=4):',
      '    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)',
      '    ',
      '    for i, batch in enumerate(data_loader):',
      '        <<optimizer.zero_grad()>>',
      '        ',
      '        <<loss = model(batch)>>  # Missing / accumulation_steps',
      '        loss.backward()',
      '        ',
      '        if (i + 1) % accumulation_steps == 0:',
      '            optimizer.step()',
      '            <<# Missing optimizer.zero_grad() here>>',
    ],
    errors: [
      { id: 'optimizer.zero_grad()', description: 'Should be once per accumulation window, not every mini-iteration.' },
      { id: 'loss = model(batch)', description: 'Divide loss by accumulation_steps to preserve effective LR.' },
      { id: '# Missing optimizer.zero_grad() here', description: 'Call optimizer.zero_grad() after optimizer.step() to start the next window.' },
    ],
  },
  {
    title: 'RLHF Reward Model Training',
    difficulty: 'Advanced',
    code: [
      'import torch',
      'def train_reward_model(model, comparison_data):',
      '    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)',
      '    ',
      '    for batch in comparison_data:',
      '        preferred, rejected = batch',
      '        ',
      '        preferred_reward = model(preferred)',
      '        rejected_reward = model(rejected)',
      '        ',
      '        loss = -torch.log(<<torch.sigmoid(preferred_reward - rejected_reward)>>)',
      '        <<# Missing optimizer.zero_grad()>>',
      '        loss.backward()',
      '        optimizer.step()',
    ],
    errors: [
      { id: 'torch.sigmoid(preferred_reward - rejected_reward)', description: 'Loss should be averaged across the batch: wrap with .mean() or average explicitly.' },
      { id: '# Missing optimizer.zero_grad()', description: 'Call optimizer.zero_grad() before backward().' },
    ],
  },
  {
    title: 'Attention Mask Broadcasting',
    difficulty: 'Expert',
    code: [
      'import torch',
      'import torch.nn.functional as F',
      'def apply_attention_mask(attention_scores, mask):',
      '    # attention_scores: [batch, heads, seq_len, seq_len]',
      '    # mask: [batch, seq_len]',
      '    ',
      '    if mask is not None:',
      '        expanded_mask = <<mask.unsqueeze(1).unsqueeze(1)>>  # Wrong dimensions!',
      '        attention_scores = attention_scores.masked_fill(',
      '            <<expanded_mask == 0>>, -1e9)',
      '    ',
      '    return F.softmax(attention_scores, dim=-1)',
    ],
    errors: [
      { id: 'mask.unsqueeze(1).unsqueeze(1)', description: 'Wrong broadcasting; should be unsqueeze(1).unsqueeze(2) → [batch, 1, seq_len, 1] or match model expected layout.' },
      { id: 'expanded_mask == 0', description: 'Usually mask positions are where mask == 1 (padding). Ensure correct polarity.' },
    ],
  },
  {
    title: 'Prompt Injection Defense',
    difficulty: 'Intermediate',
    code: [
      'def secure_prompt_handler(user_input, system_prompt):',
      '    # Basic injection detection (brittle)',
      '    injection_patterns = <<["ignore previous", "disregard instructions"]>>',
      '    ',
      '    for pattern in injection_patterns:',
      '        if pattern in user_input.lower():',
      '            return "Potential injection detected"',
      '    ',
      '    # Construct prompt',
      '    <<full_prompt = system_prompt + "\\n\\nUser: " + user_input>>',
      '    ',
      '    return call_llm(full_prompt)',
    ],
    errors: [
      { id: '["ignore previous", "disregard instructions"]', description: 'Keyword match is brittle; use structured checks, allowlists, or a classifier.' },
      { id: 'full_prompt = system_prompt + "\\n\\nUser: " + user_input', description: 'String concatenation invites injection; use structured messages with roles instead.' },
    ],
  },
  {
    title: 'Model Evaluation with Proper Metrics',
    difficulty: 'Beginner',
    code: [
      'import numpy as np',
      'def evaluate_classification_model(y_true, y_pred):',
      '    accuracy = np.mean(y_pred == y_true)',
      '    ',
      '    # Calculate precision and recall',
      '    <<tp = fp = fn = 0>>  # These are never computed!',
      '    precision = tp / (tp + fp) if (tp + fp) > 0 else 0',
      '    recall = tp / (tp + fn) if (tp + fn) > 0 else 0',
      '    ',
      '    f1_score = <<2 * (precision * recall) / (precision + recall)>> if (precision + recall) > 0 else 0',
      '    ',
      '    return {"accuracy": accuracy, "precision": precision, "recall": recall, "f1": f1_score}',
    ],
    errors: [
      { id: 'tp = fp = fn = 0', description: 'tp/fp/fn are never computed; derive from confusion matrix first.' },
      { id: '2 * (precision * recall) / (precision + recall)', description: 'F1 formula is fine only if precision/recall are computed from correct counts.' },
    ],
  },
  {
    title: 'Vector Database Optimization',
    difficulty: 'Intermediate',
    code: [
      'import faiss, numpy as np',
      'def build_optimized_vector_index(documents, embedding_model):',
      '    embeddings = []',
      '    ',
      '    for doc in documents:',
      '        embedding = embedding_model.encode(doc)',
      '        embeddings.append(embedding)',
      '    ',
      '    # Initialize FAISS index',
      '    dimension = <<embedding.shape[0]>>  # Loop variable scope issue',
      '    index = faiss.IndexFlatL2(dimension)',
      '    ',
      '    embeddings_array = <<np.array(embeddings)>>  # Wrong dtype',
      '    index.add(embeddings_array)',
      '    ',
      '    return index',
    ],
    errors: [
      { id: 'embedding.shape[0]', description: "Using 'embedding' after the loop; use embeddings[0].shape[0] (ensure non-empty)." },
      { id: 'np.array(embeddings)', description: 'FAISS expects float32; use np.asarray(embeddings, dtype=np.float32).' },
    ],
  },
]

export default studentModeQuestions;