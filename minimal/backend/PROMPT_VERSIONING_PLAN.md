# Prompt Versioning and Test Dataset Management Plan

This document outlines a plan for managing prompt versions and test datasets in the database.

## Long-Term Goal

The goal is to have a robust system for tracking changes to prompts and for creating and retrieving test datasets based on prompt versions. This will allow for systematic evaluation of prompt changes and for regression testing.

## Best Practices

### 1. Database Schema

It is recommended to add a `prompt_version` column to the `enhanced_step_responses` table. This column would store a string that identifies the version of the prompts used for that run (e.g., "v1", "v2", "refactor-test-1").

**SQL Schema Change:**

```sql
ALTER TABLE enhanced_step_responses
ADD COLUMN prompt_version TEXT;
```

To manage database schema changes in a systematic and safe way, it is highly recommended to use a database migration tool like **Alembic**. Alembic allows you to manage your schema changes in versioned scripts, which makes it easy to upgrade and downgrade your database schema as your application evolves.

### 2. Test Dataset Management

With the `prompt_version` column in place, you can easily create and retrieve test datasets from the database.

**Example SQL Query:**

To retrieve all runs for a specific prompt version, you can use the following SQL query:

```sql
SELECT *
FROM enhanced_step_responses
WHERE prompt_version = 'v2';
```

You can also create test datasets by selecting specific topics from a given prompt version:

```sql
SELECT *
FROM enhanced_step_responses
WHERE prompt_version = 'v1'
  AND topic IN ('Quadratic equations', 'Executive assistant meeting scheduling');
```

### 3. Pipeline Integration

The pipeline script (`corrected_7step_pipeline.py`) should be updated to accept a `prompt_version` argument. This argument would then be passed to the database layer and stored in the `prompt_version` column for each step of the pipeline run.

This will ensure that all data generated by the pipeline is correctly tagged with the prompt version.
